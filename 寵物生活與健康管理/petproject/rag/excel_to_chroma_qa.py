
# excel_to_chroma_qa.py (Chroma v0.5+ PersistentClient)
import argparse
import os
import glob
import uuid
from typing import Iterable, Dict
import pandas as pd

import chromadb
from sentence_transformers import SentenceTransformer
from tqdm import tqdm

def iter_excel_files(input_path: str) -> Iterable[str]:
    if os.path.isdir(input_path):
        for ext in ("*.xlsx", "*.xls", "*.xlsm"):
            for p in glob.glob(os.path.join(input_path, ext)):
                yield p
    else:
        yield input_path

def load_sheets(file_path: str) -> Dict[str, pd.DataFrame]:
    try:
        return pd.read_excel(file_path, sheet_name=None, dtype=str)
    except Exception:
        return pd.read_excel(file_path, sheet_name=None, dtype=str)

def main():
    ap = argparse.ArgumentParser(description="æŠŠ FAQ é¡å‹ Excelï¼ˆQuestion/Answerï¼‰è½‰ç‚º Chroma å‘é‡åº«")
    ap.add_argument("--input", required=True, help="Excel æª”æˆ–è³‡æ–™å¤¾")
    ap.add_argument("--persist_dir", default="chroma_db", help="Chroma è³‡æ–™å¤¾ï¼ˆæœƒè‡ªå‹•å»ºç«‹ï¼‰")
    ap.add_argument("--collection", default="faq_collection", help="é›†åˆåç¨±")
    ap.add_argument("--model_name", default="BAAI/bge-small-zh-v1.5",
                    help="å¥å‘é‡æ¨¡å‹ï¼ˆå¯å¡«æœ¬æ©Ÿç›®éŒ„è·¯å¾‘ä»¥é›¢ç·šä½¿ç”¨ï¼‰")
    ap.add_argument("--batch_size", type=int, default=128)
    ap.add_argument("--q_col", default="Question")
    ap.add_argument("--a_col", default="Answer")
    args = ap.parse_args()

    print(f"[Info] è¼‰å…¥æ¨¡å‹ï¼š{args.model_name}")
    embedder = SentenceTransformer(args.model_name)

    # âœ… New Chroma API
    client = chromadb.PersistentClient(path=args.persist_dir)
    coll = client.get_or_create_collection(args.collection)

    total_docs = 0
    for file in iter_excel_files(args.input):
        sheets = load_sheets(file)
        print(f"\n[File] {file} -> {len(sheets)} å€‹å·¥ä½œè¡¨")
        for sheet_name, df in sheets.items():
            if not isinstance(df, pd.DataFrame) or df.empty:
                continue
            if args.q_col not in df.columns or args.a_col not in df.columns:
                print(f"  - è·³é {sheet_name}ï¼ˆæ‰¾ä¸åˆ°æ¬„ä½ {args.q_col}/{args.a_col}ï¼‰")
                continue

            texts, metadatas = [], []
            for idx, row in df.iterrows():
                q = str(row.get(args.q_col, "") or "").strip()
                a = str(row.get(args.a_col, "") or "").strip()
                if not (q or a):
                    continue
                content = f"å•é¡Œï¼š{q}\nç­”æ¡ˆï¼š{a}"
                texts.append(content)
                metadatas.append({
                    "source_file": os.path.basename(file),
                    "sheet": sheet_name,
                    "row_index": int(idx),
                    "qa_question": q,
                    "qa_answer": a
                })

            if not texts:
                continue

            ids = [str(uuid.uuid4()) for _ in texts]

            embeddings = []
            for i in tqdm(range(0, len(texts), args.batch_size), desc=f"Embedding [{sheet_name}]"):
                batch = texts[i:i+args.batch_size]
                emb = embedder.encode(batch, normalize_embeddings=True).tolist()
                embeddings.extend(emb)

            coll.add(ids=ids, documents=texts, metadatas=metadatas, embeddings=embeddings)
            print(f"  - {sheet_name} åŠ å…¥ {len(texts)} ç­†")
            total_docs += len(texts)

    print(f"\nâœ… å®Œæˆï¼Œç¸½è¨ˆåŠ å…¥ {total_docs} ç­†åˆ°é›†åˆï¼š{args.collection}")
    print(f"ğŸ“ è³‡æ–™åº«ç›®éŒ„ï¼š{os.path.abspath(args.persist_dir)}")

if __name__ == "__main__":
    main()
